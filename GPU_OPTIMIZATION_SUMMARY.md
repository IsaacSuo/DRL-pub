# GPUæ€§èƒ½ä¼˜åŒ–æ€»ç»“

## å·²å®ç°çš„ä¼˜åŒ–

### 1. â­ GPUå¸¸é©»å¼ é‡çš„Replay Buffer (æœ€é«˜ä¼˜å…ˆçº§)
**é¢„æœŸæ”¶ç›Š**: å‡å°‘60-80%çš„CPU-GPUæ•°æ®ä¼ è¾“æ—¶é—´

**ä¿®æ”¹æ–‡ä»¶**: `agent/replay_buffer.py`

**å…³é”®æ”¹è¿›**:
- ä½¿ç”¨ `tf.Variable` åœ¨GPUä¸Šé¢„åˆ†é…æ‰€æœ‰å†…å­˜
- `sample()` æ–¹æ³•ä½¿ç”¨ `@tf.function` ç¼–è¯‘,å…¨éƒ¨æ“ä½œåœ¨GPUä¸Šå®Œæˆ
- é›¶CPU-GPUæ‹·è´,æ‰€æœ‰æ•°æ®ä¿æŒåœ¨GPUå†…å­˜ä¸­

**ä»£ç ç¤ºä¾‹**:
```python
# æ—§ç‰ˆæœ¬ - æ¯æ¬¡é‡‡æ ·éƒ½è¿›è¡ŒCPU->GPUä¼ è¾“
return (
    tf.convert_to_tensor(states_batch, dtype=tf.float32),  # 5æ¬¡CPU->GPUä¼ è¾“
    ...
)

# æ–°ç‰ˆæœ¬ - å…¨åœ¨GPUä¸Š,é›¶æ‹·è´
states_batch = tf.gather(self.states, indices)  # GPUä¸Šç›´æ¥gather
```

---

### 2. â­ ä¼˜åŒ–Targetç½‘ç»œåŒæ­¥ (ä½å®ç°éš¾åº¦,é«˜æ”¶ç›Š)
**é¢„æœŸæ”¶ç›Š**: å‡å°‘90%çš„åŒæ­¥æ—¶é—´ (ä»~10msé™è‡³~1ms)

**ä¿®æ”¹æ–‡ä»¶**:
- `model/dqn_mlp.py:91-103`
- `model/ddqn_mlp.py:91-103`

**å…³é”®æ”¹è¿›**:
- ä½¿ç”¨ `@tf.function` ç¼–è¯‘åŒæ­¥æ“ä½œ
- ç›´æ¥åœ¨GPUä¸Šè¿›è¡Œæƒé‡æ‹·è´,æ— CPUä¸­è½¬
- åˆ†ç¦»æœ‰æ‰“å°å’Œæ— æ‰“å°ç‰ˆæœ¬

**ä»£ç å¯¹æ¯”**:
```python
# æ—§ç‰ˆæœ¬ - è§¦å‘GPU->CPU->GPUä¼ è¾“
def sync(self):
    self.target_model.set_weights(self.online_model.get_weights())

# æ–°ç‰ˆæœ¬ - çº¯GPUæ“ä½œ
@tf.function
def sync(self):
    for target_var, online_var in zip(
        self.target_model.trainable_variables,
        self.online_model.trainable_variables
    ):
        target_var.assign(online_var)  # GPUå†…å­˜æ“ä½œ
```

---

### 3. â­ XLAç¼–è¯‘ä¼˜åŒ– (ä½å®ç°éš¾åº¦,ä¸­ç­‰æ”¶ç›Š)
**é¢„æœŸæ”¶ç›Š**: æå‡5-15%çš„è®¡ç®—é€Ÿåº¦

**ä¿®æ”¹æ–‡ä»¶**:
- `policy/dqn.py:10`
- `policy/ddqn.py:56`
- `train_dqn_notebook.ipynb` (cell-1)

**å…³é”®æ”¹è¿›**:
- ä¸ºè®­ç»ƒæ­¥å‡½æ•°å¯ç”¨ `jit_compile=True`
- å…¨å±€è®¾ç½®XLAä¼˜åŒ–: `tf.config.optimizer.set_jit(True)`
- ç¯å¢ƒå˜é‡: `TF_XLA_FLAGS=--tf_xla_auto_jit=2`

**ä»£ç ç¤ºä¾‹**:
```python
# æ—§ç‰ˆæœ¬
@tf.function
def _fit_step(self, ...):
    ...

# æ–°ç‰ˆæœ¬ - å¯ç”¨XLA JITç¼–è¯‘
@tf.function(jit_compile=True)
def _fit_step(self, ...):
    ...
```

---

### 4. ğŸ”§ GPUå†…å­˜ç®¡ç†ä¼˜åŒ–
**ä¿®æ”¹æ–‡ä»¶**:
- `trainer.py:31-39`
- `train_dqn_notebook.ipynb` (cell-1)

**å…³é”®æ”¹è¿›**:
- å¯ç”¨GPUå†…å­˜æŒ‰éœ€å¢é•¿,é˜²æ­¢OOM
- è‡ªåŠ¨æ£€æµ‹GPUè®¾å¤‡
- çº¿ç¨‹é…ç½®è‡ªåŠ¨ä¼˜åŒ–

**ä»£ç **:
```python
gpus = tf.config.list_physical_devices('GPU')
if gpus:
    for gpu in gpus:
        tf.config.experimental.set_memory_growth(gpu, True)
```

---

## æ–‡ä»¶ä¿®æ”¹æ¸…å•

| æ–‡ä»¶ | ä¿®æ”¹å†…å®¹ | ä¼˜å…ˆçº§ |
|------|---------|--------|
| `agent/replay_buffer.py` | GPUå¸¸é©»å¼ é‡å®ç° | â­â­â­â­â­ |
| `agent/kytolly.py` | ä¼ é€’deviceå‚æ•° | â­â­â­â­â­ |
| `model/dqn_mlp.py` | ä¼˜åŒ–syncå‡½æ•° | â­â­â­ |
| `model/ddqn_mlp.py` | ä¼˜åŒ–syncå‡½æ•° | â­â­â­ |
| `policy/dqn.py` | å¯ç”¨XLAç¼–è¯‘ | â­â­â­ |
| `policy/ddqn.py` | å¯ç”¨XLAç¼–è¯‘ | â­â­â­ |
| `trainer.py` | GPUé…ç½®+ä¼ é€’device | â­â­â­â­ |
| `train_dqn_notebook.ipynb` | é›†æˆæ‰€æœ‰ä¼˜åŒ– | â­â­â­â­ |

---

## å¤‡ä»½æ–‡ä»¶

- `agent/replay_buffer_cpu.py.backup` - åŸå§‹CPUç‰ˆæœ¬çš„replay buffer

---

## ä½¿ç”¨æ–¹æ³•

### æ–¹æ³•1: ä½¿ç”¨ä¼˜åŒ–åçš„Notebook
```bash
jupyter notebook train_dqn_notebook.ipynb
```

Notebookå·²è‡ªåŠ¨é…ç½®æ‰€æœ‰ä¼˜åŒ–,æ— éœ€é¢å¤–è®¾ç½®ã€‚

### æ–¹æ³•2: ä½¿ç”¨gpu_optimizeæ¨¡å— (å¯é€‰)
```python
from gpu_optimize import configure_gpu_optimization

configure_gpu_optimization(
    enable_xla=True,
    enable_mixed_precision=False,  # å¯é€‰
    memory_growth=True,
    verbose=True
)
```

### æ–¹æ³•3: æ‰‹åŠ¨è®¾ç½®ç¯å¢ƒå˜é‡
```bash
export TF_XLA_FLAGS=--tf_xla_auto_jit=2
export TF_ENABLE_AUTO_MIXED_PRECISION=1  # å¯é€‰
python your_training_script.py
```

---

## æ€§èƒ½åŸºå‡†æµ‹è¯•

åœ¨æœåŠ¡å™¨ä¸Šè¿è¡Œä»¥ä¸‹å‘½ä»¤è¿›è¡ŒåŸºå‡†æµ‹è¯•:

```bash
# è¿è¡ŒåŸºå‡†æµ‹è¯•
python gpu_optimize.py
```

é¢„æœŸè¾“å‡º:
```
âœ… XLA compilation enabled (expected 5-15% speedup)
âœ… Configured 1 GPU(s) with memory growth enabled
âœ… Benchmark complete: X.XXX ms/iteration
   Throughput: XXX.X iterations/second
```

---

## é¢„æœŸæ€»ä½“æ€§èƒ½æå‡

| ä¼˜åŒ–é¡¹ | é¢„æœŸæå‡ | çŠ¶æ€ |
|--------|---------|------|
| GPU Replay Buffer | 60-80% I/Oä¼˜åŒ– | âœ… å·²å®ç° |
| Targetç½‘ç»œåŒæ­¥ | 90% åŒæ­¥æ—¶é—´å‡å°‘ | âœ… å·²å®ç° |
| XLAç¼–è¯‘ | 5-15% è®¡ç®—åŠ é€Ÿ | âœ… å·²å®ç° |
| GPUå†…å­˜ç®¡ç† | é¿å…OOMé”™è¯¯ | âœ… å·²å®ç° |
| **æ€»ä½“é¢„ä¼°** | **2-3å€è®­ç»ƒé€Ÿåº¦æå‡** | âœ… å·²å°±ç»ª |

---

## æœªå®ç°çš„è¿›é˜¶ä¼˜åŒ– (å¯é€‰)

### 1. æ··åˆç²¾åº¦è®­ç»ƒ
- **æ”¶ç›Š**: 20-30% (éœ€è¦Tensor Coreæ”¯æŒ)
- **é£é™©**: å¯èƒ½å½±å“æ•°å€¼ç¨³å®šæ€§
- **å®ç°**: åœ¨ `gpu_optimize.py` ä¸­è®¾ç½® `enable_mixed_precision=True`

### 2. å¼‚æ­¥ç¯å¢ƒæ‰§è¡Œ
- **æ”¶ç›Š**: 2-3å€æ€»ä½“æå‡
- **éš¾åº¦**: é«˜
- **é€‚ç”¨**: å¤æ‚ç¯å¢ƒ (CartPoleå¯èƒ½ä¸é€‚ç”¨)

### 3. ç¼–è¯‘æ•´ä¸ªè®­ç»ƒå¾ªç¯
- **æ”¶ç›Š**: 30-50% Pythonå¼€é”€å‡å°‘
- **éš¾åº¦**: ä¸­ç­‰
- **æ³¨æ„**: éœ€è¦å°†æ•´ä¸ª `update_policy` è½¬æ¢ä¸º `@tf.function`

---

## éªŒè¯ä¼˜åŒ–æ•ˆæœ

### 1. æ£€æŸ¥GPUä½¿ç”¨ç‡
```bash
# åœ¨è®­ç»ƒæ—¶è¿è¡Œ
watch -n 1 nvidia-smi
```

é¢„æœŸGPUåˆ©ç”¨ç‡åº”è¯¥åœ¨80-100%ä¹‹é—´ã€‚

### 2. å¯¹æ¯”è®­ç»ƒæ—¶é—´
```python
import time

# è®°å½•è®­ç»ƒå¼€å§‹æ—¶é—´
start_time = time.time()

# è¿è¡Œè®­ç»ƒ
trainer.train_dqn(train_cfg, env, cb)

# è®¡ç®—æ€»æ—¶é—´
total_time = time.time() - start_time
print(f"è®­ç»ƒè€—æ—¶: {total_time:.2f} ç§’")
```

### 3. æ£€æŸ¥TensorBoardæ—¥å¿—
```bash
tensorboard --logdir=logs/
```

æŸ¥çœ‹:
- è®­ç»ƒé€Ÿåº¦ (steps/sec)
- GPUå†…å­˜ä½¿ç”¨
- è®­ç»ƒæ›²çº¿æ”¶æ•›é€Ÿåº¦

---

## æ•…éšœæ’æŸ¥

### é—®é¢˜1: XLAç¼–è¯‘å¤±è´¥
**ç—‡çŠ¶**: è­¦å‘Šä¿¡æ¯ "XLA compilation failed"

**è§£å†³**:
```python
# ç¦ç”¨XLAä»…ç”¨äºæµ‹è¯•
@tf.function(jit_compile=False)
```

### é—®é¢˜2: GPUå†…å­˜æº¢å‡º
**ç—‡çŠ¶**: "ResourceExhaustedError: OOM when allocating tensor"

**è§£å†³**:
```python
# å‡å°replay bufferå¤§å°
self.replay_buffer = OptimizedReplayBuffer(
    max_size=10000,  # ä»50000å‡å°‘
    state_dim=4,
    device=device
)
```

### é—®é¢˜3: CPU fallbackè­¦å‘Š
**ç—‡çŠ¶**: "Falling back to CPU"

**è§£å†³**: æ£€æŸ¥CUDAå’ŒcuDNNç‰ˆæœ¬æ˜¯å¦åŒ¹é…TensorFlowç‰ˆæœ¬:
```bash
python -c "import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))"
```

---

## ä¸‹ä¸€æ­¥å»ºè®®

1. **ç«‹å³æµ‹è¯•**: åœ¨GPUæœåŠ¡å™¨ä¸Šè¿è¡Œä¼˜åŒ–åçš„notebook
2. **æ€§èƒ½ç›‘æ§**: ä½¿ç”¨ `nvidia-smi` ç›‘æ§GPUåˆ©ç”¨ç‡
3. **å¯¹æ¯”åŸºå‡†**: ä¸åŸå§‹ç‰ˆæœ¬å¯¹æ¯”è®­ç»ƒæ—¶é—´
4. **è°ƒä¼˜å‚æ•°**: æ ¹æ®GPUå†…å­˜è°ƒæ•´bufferå¤§å°
5. **è€ƒè™‘è¿›é˜¶**: å¦‚æœCartPoleè®­ç»ƒé€Ÿåº¦ä»ä¸å¤Ÿ,è€ƒè™‘æ··åˆç²¾åº¦è®­ç»ƒ

---

**åˆ›å»ºæ—¥æœŸ**: 2025-11-08
**ä¼˜åŒ–ç‰ˆæœ¬**: v1.0
**å…¼å®¹æ€§**: TensorFlow 2.12+, CUDA 11.8+
